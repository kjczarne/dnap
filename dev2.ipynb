{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Baselines"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNABERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install einops transformers peft omegaconf torch evaluate accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at zhihan1996/DNA_bert_6 were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zhihan1996/DNA_bert_6\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"zhihan1996/DNA_bert_6\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 1, 3]])\n",
      "torch.Size([768])\n",
      "torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "dna = \"ACGTAGCATCGGATCTATCTATCGACACTTGGTTATCGATCTACGAGCATCTCGTTAGC\"\n",
    "inputs = tokenizer(dna, return_tensors = 'pt')[\"input_ids\"]\n",
    "print(inputs)\n",
    "model = model.to(\"cuda\")\n",
    "hidden_states = model(inputs.to(\"cuda\"))[0] # [1, sequence_length, 768]\n",
    "\n",
    "# embedding with mean pooling\n",
    "embedding_mean = torch.mean(hidden_states[0], dim=0)\n",
    "print(embedding_mean.shape) # expect to be 768\n",
    "\n",
    "# embedding with max pooling\n",
    "embedding_max = torch.max(hidden_states[0], dim=0)[0]\n",
    "print(embedding_max.shape) # expect to be 768"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nucleotide-Transformer from InstaDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (1, 10, 1280)\n",
      "Embeddings per token: [[[ 0.09300065  0.34371722  0.3723031  ... -0.40012842 -0.15076053\n",
      "    0.07454759]\n",
      "  [-0.6912435   1.262262   -0.16280103 ... -0.8053381  -0.19705848\n",
      "   -2.1087687 ]\n",
      "  [-0.5719655   1.1624311  -0.3457358  ... -0.717227   -0.26854762\n",
      "   -2.157653  ]\n",
      "  ...\n",
      "  [-0.67676777  1.4332684  -0.44941118 ... -0.9559051  -0.67712104\n",
      "   -2.0696611 ]\n",
      "  [-0.62161577  1.1120433  -0.14762029 ... -0.9116353  -0.41632363\n",
      "   -1.9834615 ]\n",
      "  [-0.902306    1.1265255  -0.30772838 ... -0.97984993 -0.25661114\n",
      "   -2.2153628 ]]]\n",
      "Mean sequence embeddings: tensor([[-0.5551,  1.1327, -0.1687,  ..., -0.7917, -0.3625, -1.8504]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Import the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"InstaDeepAI/nucleotide-transformer-500m-human-ref\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"InstaDeepAI/nucleotide-transformer-500m-human-ref\")\n",
    "\n",
    "# Create a dummy dna sequence and tokenize it\n",
    "sequences = ['ATTCTG' * 9]\n",
    "tokens_ids = tokenizer.batch_encode_plus(sequences, return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Compute the embeddings\n",
    "attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "torch_outs = model(\n",
    "    tokens_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    encoder_attention_mask=attention_mask,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "# Compute sequences embeddings\n",
    "embeddings = torch_outs['hidden_states'][-1].detach().numpy()\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embeddings per token: {embeddings}\")\n",
    "\n",
    "# Compute mean embeddings per sequence\n",
    "mean_sequence_embeddings = torch.sum(attention_mask.unsqueeze(-1)*embeddings, axis=-2)/torch.sum(attention_mask, axis=-1)\n",
    "print(f\"Mean sequence embeddings: {mean_sequence_embeddings}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = mean_sequence_embeddings[0]\n",
    "b = mean_sequence_embeddings[0]\n",
    "cos_sim = np.dot(a, b)/(np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001, 0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001, 0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001, 0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001, 0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001, 0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001, 0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001, 0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001, 0.41, 0.41, 0.41, 0.5900000000000001, 0.41, 0.5900000000000001]\n",
      "3.973262012386456\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "p_a_or_t = 0.41\n",
    "p_g_or_c = 1 - p_a_or_t\n",
    "\n",
    "probs = []\n",
    "for n in sequences[0]:\n",
    "    if n.lower() == \"a\" or n.lower() == \"t\":\n",
    "        probs.append(p_a_or_t)\n",
    "    else:\n",
    "        probs.append(p_g_or_c)\n",
    "\n",
    "print(probs)\n",
    "print(entropy(probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_seq = \"ATTATGCATCATTGATTT\"\n",
    "dnap_seq = \"ATTMHH$TTT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_of_sequence(seq: str, p_a_or_t: float = 0.41, p_g_or_c: float = 0.59):\n",
    "    probs = []\n",
    "    for n in seq:\n",
    "        if n.lower() == \"a\" or n.lower() == \"t\":\n",
    "            probs.append(p_a_or_t)\n",
    "        else:\n",
    "            probs.append(p_g_or_c)\n",
    "    return entropy(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.973262012386456"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_of_sequence(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "probability_table = {\n",
    "    \"A\": 0.0777,\n",
    "    \"C\": 0.0157,\n",
    "    \"D\": 0.0530,\n",
    "    \"E\": 0.0656,\n",
    "    \"F\": 0.0405,\n",
    "    \"G\": 0.0691,\n",
    "    \"H\": 0.0227,\n",
    "    \"I\": 0.0591,\n",
    "    \"K\": 0.0595,\n",
    "    \"L\": 0.0960,\n",
    "    \"M\": 0.0238,\n",
    "    \"N\": 0.0427,\n",
    "    \"P\": 0.0469,\n",
    "    \"Q\": 0.0393,\n",
    "    \"R\": 0.0526,\n",
    "    \"S\": 0.0694,\n",
    "    \"T\": 0.0550,\n",
    "    \"V\": 0.0667,\n",
    "    \"W\": 0.0118,\n",
    "    \"Y\": 0.0311,\n",
    "    \"M\": 0.0001,  # smallest non-zero probability at this level of precision\n",
    "    \"$\": 0.0001\n",
    "}\n",
    "\n",
    "def entropy_of_dnap_sequence(seq: str, probability_table: dict):\n",
    "    probs = []\n",
    "    for n in seq:\n",
    "        prob = probability_table[n.upper()]\n",
    "        probs.append(prob)\n",
    "    return entropy(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9745999999999999"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(probability_table.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.016509206004858"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_of_dnap_sequence(dnap_seq, probability_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "\n",
    "def dnap_tokenize(seq: str):\n",
    "    # find boundaries of the coding sequence\n",
    "    start = seq.lower().find(\"atg\")\n",
    "    stop = seq.lower().find(\"tga\")\n",
    "    protein_seq = str(Seq(seq[start:stop]).translate())\n",
    "    return seq[0:start-1] + protein_seq + \"$\" + seq[stop+3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ATMHH$TTT'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnap_tokenize(dna_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./promoter_detection/train.csv\", header=0)\n",
    "df_val = pd.read_csv(\"./promoter_detection/dev.csv\", header=0)\n",
    "df_test = pd.read_csv(\"./promoter_detection/test.csv\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TATAATAATAACGAAGATGAGACGACAGTCGACAAGAAAAGCACCA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAAGCCCGAGCGGCGGCCACGCCTCGGTGGCGATTTTATTAGCGCT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGTCCGCGATATTCTGAGGGGACTTTCGACACAAAAAAGTTGACAC...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ACCCCCCGGCCCCGCCCCACAGACCCCTCCAGTGGTCCCCCGGCCA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGGTCTTTGGTCCCCCAACCCTGTGCTCTTTCCACTTAAATCCCGA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sequence  label\n",
       "0  TATAATAATAACGAAGATGAGACGACAGTCGACAAGAAAAGCACCA...      0\n",
       "1  AAAGCCCGAGCGGCGGCCACGCCTCGGTGGCGATTTTATTAGCGCT...      1\n",
       "2  AGTCCGCGATATTCTGAGGGGACTTTCGACACAAAAAAGTTGACAC...      0\n",
       "3  ACCCCCCGGCCCCGCCCCACAGACCCCTCCAGTGGTCCCCCGGCCA...      1\n",
       "4  AGGTCTTTGGTCCCCCAACCCTGTGCTCTTTCCACTTAAATCCCGA...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (100, 51, 1280)\n",
      "Embeddings per token: [[[ 7.05086812e-02  2.90539056e-01  3.26251954e-01 ... -5.54491937e-01\n",
      "   -2.04697158e-02 -1.46248303e-02]\n",
      "  [-4.15493064e-02  4.68324691e-01 -4.76777941e-01 ... -1.13392413e+00\n",
      "    1.00057375e+00 -8.60289812e-01]\n",
      "  [-1.06958918e-01 -5.47006130e-01  5.48749149e-01 ... -1.94588110e-01\n",
      "   -4.50046688e-01 -1.61181211e+00]\n",
      "  ...\n",
      "  [ 6.28693774e-02  7.46243656e-01 -2.83405870e-01 ... -2.47954354e-01\n",
      "   -2.94601798e-01  1.76721886e-01]\n",
      "  [-6.48806468e-02  8.48259211e-01 -3.03161860e-01 ... -2.40503669e-01\n",
      "   -1.08828627e-01 -8.01098585e-01]\n",
      "  [-5.76559663e-01  6.70304894e-01 -4.45232362e-01 ...  1.14153378e-01\n",
      "    3.67443502e-01 -2.37486780e-01]]\n",
      "\n",
      " [[ 1.15056746e-01  2.23919272e-01  5.36945701e-01 ... -6.04434431e-01\n",
      "   -2.54429616e-02  1.77233116e-04]\n",
      "  [-1.32668555e-01  7.65201211e-01 -6.59714341e-01 ... -6.14052534e-01\n",
      "    9.20189738e-01 -1.16649196e-02]\n",
      "  [ 2.50105560e-01  6.90061927e-01 -6.83128417e-01 ...  4.29264992e-01\n",
      "    9.43177402e-01 -2.20542714e-01]\n",
      "  ...\n",
      "  [ 2.03581095e-01  4.78860408e-01  3.63588512e-01 ... -6.65233791e-01\n",
      "    1.19693840e+00 -2.38273680e-01]\n",
      "  [-6.41820394e-03  9.74430591e-02  2.25793868e-01 ...  1.27662882e-01\n",
      "    7.24550113e-02 -2.76536644e-01]\n",
      "  [ 1.20803334e-01  2.17218101e-01  1.30972594e-01 ... -6.52998447e-01\n",
      "   -1.17812961e-01 -3.02749723e-01]]\n",
      "\n",
      " [[ 2.81987619e-02  1.58664107e-01  4.69553411e-01 ... -3.79371852e-01\n",
      "    1.03859603e-02 -5.32887205e-02]\n",
      "  [-5.74469328e-01  5.89872450e-02  2.70757169e-01 ...  1.87878951e-01\n",
      "   -3.86696607e-01  3.35845113e-01]\n",
      "  [-6.72222793e-01  4.25495863e-01  2.53199667e-01 ... -7.71645725e-01\n",
      "    8.77693966e-02  2.01274797e-01]\n",
      "  ...\n",
      "  [-5.87028742e-01  8.76949877e-02  1.14252351e-01 ... -4.16849442e-02\n",
      "    1.10762739e+00 -5.01411259e-01]\n",
      "  [-2.66669095e-01  5.89534603e-02 -5.81506371e-01 ...  5.82336895e-02\n",
      "    4.83530551e-01 -7.17915595e-03]\n",
      "  [-1.12804329e+00  3.50112170e-02 -9.96204540e-02 ... -1.30131379e-01\n",
      "    1.15000939e+00  4.75436784e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.53806601e-02  1.62267178e-01  4.47594345e-01 ... -3.28787237e-01\n",
      "   -6.69293255e-02  2.57838387e-02]\n",
      "  [ 1.84508312e+00 -3.03619653e-01 -1.10910118e-01 ... -1.66943610e-01\n",
      "    3.88134986e-01 -3.81192952e-01]\n",
      "  [-4.30811584e-01  1.23953581e+00 -6.26455903e-01 ... -7.58572638e-01\n",
      "    1.03097558e+00 -2.10926030e-02]\n",
      "  ...\n",
      "  [-3.01739052e-02  7.48734951e-01  7.93412775e-02 ...  1.82640683e-02\n",
      "   -2.26233862e-02  3.26458335e-01]\n",
      "  [-1.38268507e+00 -5.88447750e-01 -8.78681898e-01 ...  3.26045781e-01\n",
      "    6.23475993e-03 -7.75163949e-01]\n",
      "  [-4.84723598e-02  5.46035647e-01  5.57239711e-01 ...  2.66811103e-01\n",
      "    4.51020956e-01 -5.49111724e-01]]\n",
      "\n",
      " [[ 7.46135712e-02  2.38352478e-01  3.97586375e-01 ... -4.63341981e-01\n",
      "    3.02867815e-02  3.80599573e-02]\n",
      "  [ 5.29260218e-01  4.62064058e-01  2.77596295e-01 ... -3.63631278e-01\n",
      "   -1.16450810e+00 -4.52070087e-01]\n",
      "  [-7.75615824e-03  5.08343339e-01  2.13562042e-01 ...  2.56148189e-01\n",
      "   -1.01900153e-01 -1.14771917e-01]\n",
      "  ...\n",
      "  [ 1.33024558e-01  3.00026804e-01  3.66372317e-01 ... -2.19947234e-01\n",
      "   -2.66079605e-01 -9.52461183e-01]\n",
      "  [-6.41414464e-01  4.52457935e-01  1.03350997e+00 ... -1.02574587e+00\n",
      "   -2.02577665e-01 -1.35254180e+00]\n",
      "  [-4.07976240e-01 -5.44200361e-01  1.56929761e-01 ... -1.41780570e-01\n",
      "   -4.48065758e-01 -5.44365823e-01]]\n",
      "\n",
      " [[ 2.13163979e-02  2.52913952e-01  2.36506313e-01 ... -4.60092664e-01\n",
      "   -2.30966043e-02  2.22593416e-02]\n",
      "  [-2.43467614e-01  1.25962067e+00  7.82576680e-01 ... -3.08231562e-01\n",
      "   -6.98513687e-02 -1.67381942e-01]\n",
      "  [-4.32899833e-01  7.24364638e-01  1.59455061e+00 ... -1.34262711e-01\n",
      "   -6.93395674e-01 -3.03761959e-01]\n",
      "  ...\n",
      "  [ 8.42916369e-01  8.39237452e-01 -1.30461782e-01 ... -1.55279234e-01\n",
      "   -1.23729959e-01 -2.89866537e-01]\n",
      "  [ 6.85875475e-01 -4.76752073e-01  3.12158734e-01 ... -2.36502916e-01\n",
      "    9.78509605e-01 -1.35419965e+00]\n",
      "  [ 1.13145423e+00  1.92730680e-01 -9.32882503e-02 ... -7.29836300e-02\n",
      "   -4.18177068e-01 -1.63453251e-01]]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import torch\n",
    "\n",
    "# Import the tokenizer and the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"InstaDeepAI/nucleotide-transformer-500m-human-ref\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"InstaDeepAI/nucleotide-transformer-500m-human-ref\")\n",
    "\n",
    "tokens_ids = tokenizer.batch_encode_plus(df_train[\"sequence\"][0:100], return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Compute the embeddings\n",
    "attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "torch_outs = model(\n",
    "    tokens_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    encoder_attention_mask=attention_mask,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "# Compute sequences embeddings\n",
    "embeddings = torch_outs['hidden_states'][-1].detach().numpy()\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Embeddings per token: {embeddings}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=10, learning_rate=1.0)\n",
    "clf = clf.fit(embeddings.reshape((100, 51 * 1280)), df_train['label'][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_ids = tokenizer.batch_encode_plus(df_test[\"sequence\"][0:100], return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "# Compute the embeddings\n",
    "attention_mask = tokens_ids != tokenizer.pad_token_id\n",
    "torch_outs = model(\n",
    "    tokens_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    encoder_attention_mask=attention_mask,\n",
    "    output_hidden_states=True\n",
    ")\n",
    "\n",
    "# Compute sequences embeddings\n",
    "embeddings = torch_outs['hidden_states'][-1].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(embeddings.reshape((100, 51 * 1280)), df_test['label'][0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 51, 1280)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "class ClassifierHead(nn.Module):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.fc1 = nn.Linear(1280, 51)\n",
    "        self.fc2 = nn.Linear(2601, 1)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x).flatten(start_dim=1)\n",
    "        x = self.fc2(x)\n",
    "        return F.sigmoid(x)\n",
    "\n",
    "clf = ClassifierHead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def train_closure(model: nn.Module,\n",
    "                  optimizer: torch.optim.Optimizer,\n",
    "                  loss_fn: Callable,\n",
    "                  train_data_loader: DataLoader,\n",
    "                  labels: torch.Tensor):\n",
    "\n",
    "    def train(epoch: int):\n",
    "        batch_offset_idx = 0\n",
    "        for i, data in enumerate(train_data_loader):\n",
    "            optimizer.zero_grad()  # zero gradients for the current batch\n",
    "            print(data.shape)\n",
    "            outputs = model(data)\n",
    "            print(outputs.shape)\n",
    "            batch_right_offset = batch_offset_idx + train_data_loader.batch_size\n",
    "            if i == 10:\n",
    "                break\n",
    "            loss = loss_fn(outputs, labels[batch_offset_idx: batch_right_offset])\n",
    "            batch_offset_idx = batch_right_offset\n",
    "            optimizer.step()  # triggers weight update\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss}\")\n",
    "\n",
    "    return train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataLoader(Dataset):\n",
    "\n",
    "    def __init__(self, sequences: pd.Series, batch_size: int = 10) -> None:\n",
    "        self.x = torch.tensor(sequences)\n",
    "        self.batch_size = batch_size\n",
    "        super().__init__()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index: index + self.batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fn = train_closure(clf,\n",
    "                         torch.optim.SGD(clf.parameters(), lr=0.1),\n",
    "                         nn.BCELoss(),\n",
    "                         SequenceDataLoader(embeddings),\n",
    "                         torch.tensor(df_train[\"label\"][0:100]).unsqueeze(-1).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "Epoch: 0, Loss: 0.7219427824020386\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "Epoch: 1, Loss: 0.7219427824020386\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "Epoch: 2, Loss: 0.7219427824020386\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "Epoch: 3, Loss: 0.7219427824020386\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "torch.Size([10, 51, 1280])\n",
      "torch.Size([10, 1])\n",
      "Epoch: 4, Loss: 0.7219427824020386\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_fn(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
